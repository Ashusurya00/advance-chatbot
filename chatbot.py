import os
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser

# =========================
# ğŸ” API KEYS (TEMPORARY)
# =========================
GEMINI_API_KEY = ""
LANGCHAIN_API_KEY = ""

# =========================
# ğŸ” LangSmith Tracing
# =========================
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "Gemini-Streamlit-Chatbot"
os.environ["LANGCHAIN_API_KEY"] = LANGCHAIN_API_KEY

# =========================
# ğŸ¨ Streamlit Page Config
# =========================
st.set_page_config(
    page_title="Gemini AI Chatbot",
    page_icon="ğŸ¤–",
    layout="centered"
)

st.title("ğŸ¤– Gemini AI Chatbot")
st.caption("Powered by Google Gemini + LangChain + LangSmith")

# =========================
# ğŸ’¬ Chat History
# =========================
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display previous messages
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# =========================
# ğŸ§  Prompt Template
# =========================
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI assistant."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{question}")
])

# =========================
# ğŸ¤– LLM
# =========================
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.2,
    api_key=GEMINI_API_KEY
)

chain = prompt | llm | StrOutputParser()

# =========================
# ğŸ§‘ User Input
# =========================
user_input = st.chat_input("Ask me anything...")

if user_input:
    # Show user message
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # Generate response
    with st.chat_message("assistant"):
        with st.spinner("Thinking... ğŸ¤”"):
            response = chain.invoke({
                "question": user_input,
                "chat_history": [
                    ("human" if m["role"] == "user" else "assistant", m["content"])
                    for m in st.session_state.messages[:-1]
                ]
            })
            st.markdown(response)

    # Save assistant response
    st.session_state.messages.append({"role": "assistant", "content": response})
